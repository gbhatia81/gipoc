{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4648a1",
   "metadata": {},
   "source": [
    "# RAG using youtube subtitles\n",
    "https://python.langchain.com/docs/use_cases/question_answering/quickstart#retrieval-and-generation-retrieve\n",
    "\n",
    "### Indexing\n",
    "1. **Load**: First we need to load data using DocumentLoaders.\n",
    "2. **Split**: Text splitter breaks large Documents into smaller chunks. This is useful both for indexing data and for passing it in to a model, since large chunks are harder to search over and won’t fit in a model’s finite context window.\n",
    "3. **Store**: Vector store is used to store and index document splits to perform a search.\n",
    "\n",
    "### Retrieval and generation\n",
    "1. **Retrieve**: Given a user input, relevant splits are retrieved from storage using a Retriever.\n",
    "2. **Generate**: A ChatModel / LLM produces an answer using a prompt that includes the question and the retrieved data\n",
    "\n",
    "\n",
    "### Dependencies\n",
    "1. **OpenAI chat model and embeddings** \n",
    "2. **Chroma vector store** \n",
    "\n",
    "#### Packages (Already installed)\n",
    "```\n",
    "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai chromadb\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f4e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3a324e",
   "metadata": {},
   "source": [
    "###  Load data\n",
    "##### Use **YoutubeLoader** to load the subtitles of the video \n",
    "\n",
    "https://www.youtube.com/watch?v=_v_ZAtc06Jk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f529177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
      "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install youtube_transcript_api pytube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d965d979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2655"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=_v_ZAtc06Jk\",\n",
    "    add_video_info=True,\n",
    "    language=[\"en\", \"id\"],\n",
    "    translation=\"en\",\n",
    ")\n",
    "subtitles_data = loader.load()\n",
    "len(subtitles_data[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61d10f1",
   "metadata": {},
   "source": [
    "\n",
    "### Split the data \n",
    "Use the RecursiveCharacterTextSplitter. Set ```add_start_index=True``` so that the character index at which each split Document starts within the initial Document is preserved as metadata attribute ```“start_index”```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b22eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "## Compare the difference created by chunk overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(subtitles_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2352c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f901be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e2f9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '_v_ZAtc06Jk',\n",
       " 'title': 'German TV news',\n",
       " 'description': 'Unknown',\n",
       " 'view_count': 389077,\n",
       " 'thumbnail_url': 'https://i.ytimg.com/vi/_v_ZAtc06Jk/hqdefault.jpg?sqp=-oaymwEXCJADEOABSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLALPil2gGZCbqZ64EoExtig7j-dzw',\n",
       " 'publish_date': '2013-02-03 00:00:00',\n",
       " 'length': 199,\n",
       " 'author': 'newsglotzer',\n",
       " 'start_index': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0].metadata\n",
    "#print(all_splits[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb8d9c",
   "metadata": {},
   "source": [
    "### Store - Embed and store document splits using the Chroma vector store and OpenAIEmbeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36cf038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple ids\n",
    "ids = [str(i) for i in range(1, len(all_splits) + 1)]\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings(), ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f11d0",
   "metadata": {},
   "source": [
    "### 4. Retrieval\n",
    "LangChain defines a ``Retriever`` interface which wraps an index that can return relevant Documents given a string query.\n",
    "The most common type of Retriever is the ```VectorStoreRetriever```, which uses the ``similarity`` search capabilities of a vector store to facillitate retrieval. \n",
    "Any VectorStore can easily be turned into a ```Retriever``` with VectorStore.as_retriever():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c3868d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='You see the first german television with the \"tagesschau\" (view of the day) Ladies and gentlemen, welcome to the \"tagesschau\" At the Munich Security Conference, the United States and Russia have insist on their different positions about the syria-conflict. US-vice president Biden manifested the Syrian regime for ruined Russian Foreign Minister Sergey Lavrov on the other hand, made clear that his government further stand adhere to Assad. However Lavrov quoth first time ever with the leader of the Syrian opposition Then he agreed to meet regularly On the verge of the security conference german defence Minister de Maizière announced that about 40 German soldiers at the planned eu mission would contribute to Mali The germans have to educate pioneers which have to deactivate booby traps The german Bundestag (parliament) is expected to decide later this month on the terms, The application have to start at the begin of march. first time since the start of the military operation in Mali, the', metadata={'author': 'newsglotzer', 'description': 'Unknown', 'length': 199, 'publish_date': '2013-02-03 00:00:00', 'source': '_v_ZAtc06Jk', 'start_index': 0, 'thumbnail_url': 'https://i.ytimg.com/vi/_v_ZAtc06Jk/hqdefault.jpg?sqp=-oaymwEXCJADEOABSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLALPil2gGZCbqZ64EoExtig7j-dzw', 'title': 'German TV news', 'view_count': 389077})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "docs = retriever.invoke(\"Who are we talking about?\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6f96a",
   "metadata": {},
   "source": [
    "### 5. Generation\n",
    " **Using OpenAI chat model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a2936f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b4b0d",
   "metadata": {},
   "source": [
    "#### Pull RAG prompt from the langchain hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e0f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d944ac4",
   "metadata": {},
   "source": [
    "\n",
    "## You can define your custom template as well "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee334ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd198eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# template = \"\"\"\n",
    "#         If you don't know the answer, just say that you don't know.\n",
    "#         Don't try to make up an answer.\n",
    "#         {context}\n",
    "\n",
    "#         Question: {question}\n",
    "#         Answer:\n",
    "#         \"\"\"\n",
    "# prompt_template =  PromptTemplate(\n",
    "#         template=template,\n",
    "#         input_variables=[\n",
    "#             \"context\",\n",
    "#             \"question\",\n",
    "#         ],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b75e56",
   "metadata": {},
   "source": [
    "### Initialize RetrievalQA Chain\n",
    "```RetrievalQAChain``` combines a Retriever and a QA chain (described above). It is used to retrieve documents from a Retriever and then use a QA chain to answer a question based on the retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f1994b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The news is about the Munich Security Conference and the differing positions of the United States and Russia on the Syria conflict, the German soldiers contributing to the EU mission in Mali, French President Hollande's visit to Mali, the attack on the US embassy in Ankara, Spanish Prime Minister Rajoy's response to the slush funds allegations, the Hamburger SV's loss in the German football league, and the weather forecast.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        return_source_documents=False,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "chain.invoke({\"query\":\"What is the news about?\"})[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd34d2",
   "metadata": {},
   "source": [
    "### Create a chat bot using gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b1799",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83dbf83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [ ''' Examples ''',\n",
    "    \"What is this video about?\",\n",
    "    \"Who is being talked about?\"\n",
    "    \"Summarize top 5 events in bullet points\"\n",
    "\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "def slow_echo(message, history):\n",
    "    yield str(chain.invoke({\"query\": message})[\"result\"])\n",
    "\n",
    "demo = gr.ChatInterface(slow_echo,title=\"Mychat bot\",theme=gr.themes.Soft(),examples = examples).queue()\n",
    "demo.launch(debug=True, share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4796c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DB operations\n",
    "\n",
    "#retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "#retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"filter\":{\"start_index\":1620}})\n",
    "# retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "# docs = retriever.invoke(\"Who are we talking about?\")\n",
    "# docs\n",
    "\n",
    "# docs[0].metadata[\"author\"] = \"Varun\"\n",
    "\n",
    "# vectorstore.update_document(ids[0], docs[0])\n",
    "#print(vectorstore._collection.get(ids=[ids[0]]))\n",
    "\n",
    "# # delete the last document\n",
    "#print(\"count before\", vectorstore._collection.count())\n",
    "# vectorstore._collection.delete(ids=[ids[-1]])\n",
    "# print(\"count after\", vectorstore._collection.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
